{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1e4SQJ3g1ds_KT7zVR95TDRz_uGeXpiye",
      "authorship_tag": "ABX9TyNXSrE3RwfJ5GLQ2tvcRlhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malinphy/quick_response_generator/blob/main/sent_bert_mnr_cli5_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8pJlskmXVAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CxBHbfY-7lG",
        "outputId": "32f76d25-fcbb-49d8-ecf0-d2977ce2a5e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --quiet scann\n",
        "!pip install --quiet datasets\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow_hub as hub \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scann\n",
        "# from data_loader import data_loader\n",
        "# from negative_maker import negative_maker\n",
        "# from model import model\n",
        "import datasets\n",
        "from platform import python_version\n",
        "import os "
      ],
      "metadata": {
        "id": "rOel9SGq3soF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('python_version:', python_version())\n",
        "print('numpy version:',np.__version__)\n",
        "print('pandas version:',pd.__version__)\n",
        "print('sklearn version:',sklearn.__version__)\n",
        "print('tensorflow version:',tf.__version__)\n",
        "print('keras version',keras.__version__)\n",
        "print('tf_hub version:',hub.__version__)\n",
        "print('datasets version:',datasets.__version__)\n",
        "print('scaNN version:','1.2.8')"
      ],
      "metadata": {
        "id": "86j-y6Qwl4BE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad5cc10-810e-4bc9-aea4-64642bfa9cb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python_version: 3.7.15\n",
            "numpy version: 1.21.6\n",
            "pandas version: 1.3.5\n",
            "sklearn version: 1.0.2\n",
            "tensorflow version: 2.10.0\n",
            "keras version 2.10.0\n",
            "tf_hub version: 0.12.0\n",
            "datasets version: 2.6.1\n",
            "scaNN version: 1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class data_loader():\n",
        "    def __init__(self,partition):\n",
        "        self.partition = partition\n",
        "        \n",
        "    def frame_maker(self):\n",
        "        # 'train_eli5'\n",
        "        eli5 = datasets.load_dataset('eli5', split = self.partition)\n",
        "        df = pd.DataFrame({'title':eli5['title'], 'selftext':eli5['selftext'], 'answer':eli5['answers']})\n",
        "\n",
        "        answer_len = []\n",
        "        first_answer = []\n",
        "        for i in range(len(df)):\n",
        "            answer_len.append(len(df['answer'][i]['text']))\n",
        "            first_answer.append(df['answer'][i]['text'][0])\n",
        "\n",
        "        df['first_answer'] = first_answer\n",
        "\n",
        "        unique_answer = df['first_answer'].unique()\n",
        "        num_unique_answer = len(unique_answer)\n",
        "\n",
        "        unique_questions = df['title'].unique()\n",
        "        num_unique_questions =  len(unique_questions)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class negative_maker():\n",
        "    def __init__(self,df):\n",
        "        self.df = df \n",
        "    def neg_maker(self):\n",
        "        neg_pos = []\n",
        "        neg_title = []\n",
        "        neg_answer = []\n",
        "        for i in range(len(self.df)):\n",
        "            x = np.random.randint(0, len(self.df))\n",
        "            neg_pos.append(x)\n",
        "            neg_title.append(self.df['title'][x])\n",
        "            neg_answer.append(self.df['first_answer'][x])\n",
        "\n",
        "        self.df['neg_title'] = neg_title\n",
        "        self.df['neg_answer'] = neg_answer\n",
        "\n",
        "        return self.df\n"
      ],
      "metadata": {
        "id": "BNuYGouD4j7y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = data_loader('train_eli5').frame_maker()\n",
        "test_df = data_loader('test_eli5').frame_maker()"
      ],
      "metadata": {
        "id": "ZskaDwxMK1nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de09c3b6-78b6-479b-e316-c3deb8e4dea3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset eli5 (/root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa)\n",
            "WARNING:datasets.builder:Found cached dataset eli5 (/root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_hub = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") ## universal sentence encoder model"
      ],
      "metadata": {
        "id": "6WUx6U8z3rli"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = negative_maker(train_df).neg_maker()"
      ],
      "metadata": {
        "id": "DKoC5ZNUG0hG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### LOSS FUNCTION\n",
        "\n",
        "def distance_calc(y_true, y_pred):\n",
        "    anchor, positive, negative = tf.split(y_pred, 3, axis=1)\n",
        "    ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "    an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "    loss = ap_distance - an_distance\n",
        "    margin = 0\n",
        "    loss = tf.maximum(loss + margin, 0.0)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "HlixCkrY2Y_C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model():\n",
        "    use_hub = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "\n",
        "    anc_inp = Input(shape =(), dtype = tf.string, name = 'anchor_input')\n",
        "    pos_inp = Input(shape =(), dtype = tf.string, name = 'positive_input')\n",
        "    neg_inp = Input(shape =(), dtype = tf.string, name = 'negative_input')\n",
        "\n",
        "    use_emb = hub.KerasLayer(use_hub, trainable =True, name = 'sentence_encoder')\n",
        "\n",
        "    anc_emb = use_emb(anc_inp)\n",
        "    pos_emb = use_emb(pos_inp)\n",
        "    neg_emb = use_emb(neg_inp)\n",
        "\n",
        "    # d1_anc = Dense(256, activation = 'relu')(anc_emb)\n",
        "    # d1_pos = Dense(256, activation = 'relu')(pos_emb)\n",
        "    # d1_neg = Dense(256, activation = 'relu')(neg_emb)\n",
        "\n",
        "    final = tf.keras.layers.Concatenate(axis=-1)([anc_emb, pos_emb, neg_emb])\n",
        "    final = Dropout(0.2)(final)\n",
        "\n",
        "    return Model(inputs = [anc_inp, pos_inp, neg_inp], outputs = final)"
      ],
      "metadata": {
        "id": "bbRTlWgi5Wp3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_model = model()"
      ],
      "metadata": {
        "id": "75Q9UAOJ8JZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed7fd91-66d0-4ac5-b63c-56c3f84689b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# triplet_model.compile(\n",
        "#     optimizer = 'Adam',\n",
        "#     loss = distance_calc\n",
        "# )\n",
        "# y_dummy = np.ones(len(train_df)).reshape(-1,1)\n",
        "# triplet_model.fit([np.array(train_df['title']),\n",
        "#                    np.array(train_df['first_answer']),\n",
        "#                    np.array(train_df['neg_answer'])\n",
        "#                    ],\n",
        "#                    y_dummy,\n",
        "#                    epochs = 4,\n",
        "#                   batch_size = 64*64\n",
        "#                   )\n"
      ],
      "metadata": {
        "id": "DL4NSUyy2Y5n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# triplet_model.save_weights('drive/MyDrive/Colab Notebooks/quick_response/triplet_model_weights.h5')\n",
        "triplet_model.load_weights('drive/MyDrive/Colab Notebooks/quick_response/triplet_model_weights.h5')"
      ],
      "metadata": {
        "id": "7GJb5j_9KY_2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_emb =  triplet_model.get_layer('sentence_encoder')"
      ],
      "metadata": {
        "id": "tNWU_E0KV-QH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['title'][0]"
      ],
      "metadata": {
        "id": "h_nq8-dIi-03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d912170-346e-434b-e8d3-a21e3f110d66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why do you get chills/goosebumps from hearing large crowds sing along to songs?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### For testing purpose, all test answer will be converted into embeddings\n",
        "#### using trained embedding layer.\n",
        "\n",
        "q_0 = []\n",
        "use_emb_test = []\n",
        "for i in range(len(test_df)):\n",
        "    test_answer = test_df['first_answer'][i]\n",
        "    y = np.array(use_emb(([test_answer]))).reshape(1,512)\n",
        "    use_emb_test.append(y)\n",
        "\n",
        "use_emb_test = np.squeeze(np.array(use_emb_test), axis  =1)"
      ],
      "metadata": {
        "id": "Z7G24QwECwXb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PluAZ-ugQrez"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### vector values of the test answer embedding will be stored in the \n",
        "#### vector similarity search library scaNN\n",
        "\n",
        "searcher = scann.scann_ops_pybind.builder(use_emb_test, 40, \"dot_product\").tree(\n",
        "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
        "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
      ],
      "metadata": {
        "id": "YbFX801gdUlQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create serialize target dir\n",
        "saving_path = 'drive/MyDrive/Colab Notebooks/quick_response/scann_save'\n",
        "os.makedirs(saving_path, exist_ok=True)\n",
        "## serialize the searcher\n",
        "searcher.serialize(saving_path)"
      ],
      "metadata": {
        "id": "Pk6_-yyxZ52P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searcher = scann.scann_ops_pybind.load_searcher(saving_path)"
      ],
      "metadata": {
        "id": "0rHee_vrZ8YY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_quest = test_df['title'][2]\n",
        "test_quest_emb = np.array(use_emb(([test_quest]))).reshape(1,512)\n",
        "\n",
        "index, distance = searcher.search(test_quest_emb.ravel())\n",
        "index"
      ],
      "metadata": {
        "id": "OgH7WxbxENuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d843dd8-ab50-4add-8ce0-dd4f9a9d5a28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    2,  1621,  8615, 14549, 23917,  9816,  7135,  2823, 16688,\n",
              "       15926,  4228,   824,   633, 14433, 18935,  7729,   843,  2532,\n",
              "        2953, 11183, 16366, 13973, 16904, 12756, 16278, 23605,   334,\n",
              "        3871, 21573, 12495, 16185, 17960, 10804, 18916, 20089, 13133,\n",
              "        8927, 12362, 17914,  2470], dtype=uint32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['title'][2]"
      ],
      "metadata": {
        "id": "nFG-uIxGuAUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fb0147e-4173-44c2-fcdf-583ee3868c52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What's the difference between a bush, a shrub, and a tree?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['first_answer'][index[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "RixM0T918bEM",
        "outputId": "8c933985-d993-4bc5-8d5e-e73375fb2d36"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Shrubs and trees are both specifically *woody* plants with stems that survive throughput the winter. A tree has a clear central trunk whereas a shrub has multiple stems rising from the ground.\\n\\n'Bush' is a more general term for any plant with multiple stems rising from the ground, and that can be either woody or what's called herbaceous, herbaceous plants are ones where the stems die back completely or substantially in the winter leaving the plant with just its roots and new stems grow next spring.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alternative_question = 'Is there any difference between a bush, a shrub, and a tree?'\n",
        "alternative_embeddings = np.array(use_emb(([alternative_question]))).reshape(1,512)\n",
        "alternative_index = searcher.search(alternative_embeddings.ravel())[0][0]"
      ],
      "metadata": {
        "id": "wXnnzqOQ-oIV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['first_answer'][alternative_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Z89TREUzK5QV",
        "outputId": "d16cae02-629c-468f-9394-b57f6098afbf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Shrubs and trees are both specifically *woody* plants with stems that survive throughput the winter. A tree has a clear central trunk whereas a shrub has multiple stems rising from the ground.\\n\\n'Bush' is a more general term for any plant with multiple stems rising from the ground, and that can be either woody or what's called herbaceous, herbaceous plants are ones where the stems die back completely or substantially in the winter leaving the plant with just its roots and new stems grow next spring.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EVALUATION\n"
      ],
      "metadata": {
        "id": "iYCNu-jbKBnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "close_index = []\n",
        "for i in range(len(test_df)):\n",
        "    var1 = test_df['title'][i]\n",
        "    var1 = np.array(use_emb(([var1]))).reshape(1,512)\n",
        "    index, distance = searcher.search(var1.ravel())\n",
        "    close_index.append(index)\n",
        "\n",
        "def _compute_precision_recall(targets, predictions, k):\n",
        "\n",
        "    pred = predictions[:k]\n",
        "    num_hit = len(set(pred).intersection(set(targets)))\n",
        "    precision = float(num_hit) / len(pred)\n",
        "    recall = float(num_hit) / len(targets)\n",
        "    return precision, recall\n",
        "\n",
        "N = [1,3,5,10,20]\n",
        "for t in N:\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for i, _k in enumerate(close_index):\n",
        "        precision, recall = _compute_precision_recall([i], _k,t)\n",
        "    # print(precision)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    print('precision @',t,':', np.mean(precisions))\n",
        "    print('recalls @',t,',:', np.mean(recalls))\n",
        "    print(' ')"
      ],
      "metadata": {
        "id": "xClumfgawdsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c35442-4a82-43fb-e6dc-2f35c1c5c612"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision @ 1 : 0.23759791122715404\n",
            "recalls @ 1 ,: 0.23759791122715404\n",
            " \n",
            "precision @ 3 : 0.1299635552654482\n",
            "recalls @ 3 ,: 0.3898906657963446\n",
            " \n",
            "precision @ 5 : 0.09236292428198431\n",
            "recalls @ 5 ,: 0.4618146214099217\n",
            " \n",
            "precision @ 10 : 0.05571964751958224\n",
            "recalls @ 10 ,: 0.5571964751958225\n",
            " \n",
            "precision @ 20 : 0.032102643603133155\n",
            "recalls @ 20 ,: 0.6420528720626631\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_short = test_df[['title','first_answer']]\n",
        "test_df_short.to_csv('test_df.csv')"
      ],
      "metadata": {
        "id": "q5bwHUj3fnxb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BjPZvNlKRHP"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}